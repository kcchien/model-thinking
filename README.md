<div align="center">

<img src="assets/cover.png" alt="Model Thinking â€” æ€ç¶­æ¨¡å‹å·¥å…·ç®±" width="100%"/>

<br/>
<br/>

[![æˆæ¬Š: MIT](https://img.shields.io/badge/æˆæ¬Š-MIT-yellow.svg?style=flat-square)](LICENSE)
[![Agent Skill](https://img.shields.io/badge/Agent_Skill-é€šç”¨ç›¸å®¹-blueviolet?style=flat-square)](#-ç›¸å®¹çš„-ai-agent)
[![é ˜åŸŸ](https://img.shields.io/badge/é ˜åŸŸ-10_å¤§çŸ¥è­˜åŸŸ-34d399?style=flat-square)](#-åå¤§çŸ¥è­˜é ˜åŸŸ)
[![æ¨¡å‹](https://img.shields.io/badge/æ¨¡å‹-200+-60a5fa?style=flat-square)](#-åå¤§çŸ¥è­˜é ˜åŸŸ)
[![é›¶ä¾è³´](https://img.shields.io/badge/é›¶ä¾è³´-è£äº†å°±ç”¨-f59e0b?style=flat-square)](#-å‰ç½®æ¢ä»¶)

**æŠŠ 200+ å€‹æ€ç¶­æ¨¡å‹è£é€²ä½ çš„ AI åŠ©æ‰‹ï¼Œç³»çµ±æ€§æ“´å±•ä½ çš„æ€è€ƒç¶­åº¦ã€‚**

[å¿«é€Ÿå®‰è£](#-å¿«é€Ÿå®‰è£) Â· [ä½¿ç”¨ç¯„ä¾‹](#-ä½ å¯ä»¥æ€éº¼ç”¨) Â· [åå¤§é ˜åŸŸ](#-åå¤§çŸ¥è­˜é ˜åŸŸ) Â· [é‹ä½œåŸç†](#ï¸-é‹ä½œåŸç†)

</div>

---

ä½ åšæ±ºç­–æ™‚ï¼Œæ˜¯é ç›´è¦ºï¼Œé‚„æ˜¯æœ‰ä¸€å¥—ç³»çµ±ï¼Ÿ

å¤§å¤šæ•¸äººé¢å°è¤‡é›œå•é¡Œæ™‚ï¼Œåªæœƒç”¨è‡ªå·±æœ€ç†Ÿæ‚‰çš„é‚£ä¸€å…©å€‹è§’åº¦å»æƒ³ã€‚çµæœä¸æ˜¯ç›²é»å¤ªå¤§ï¼Œå°±æ˜¯æƒ³äº†åŠå¤©åŸåœ°æ‰“è½‰ã€‚

**Model Thinking** è®“ä½ çš„ AI åŠ©æ‰‹æˆç‚ºä¸€å€‹è£å‚™äº† 200+ å€‹æ€ç¶­æ¨¡å‹çš„æ€è€ƒå¤¥ä¼´ã€‚ä¸æ˜¯çµ¦ä½ ä¸€ä»½æ¨¡å‹æ¸…å–®è®“ä½ è‡ªå·±è®€â€”â€”è€Œæ˜¯æ ¹æ“šä½ çš„å•é¡Œï¼Œå³æ™‚æŒ‘é¸ 2-3 å€‹æœ€åˆé©çš„æ¨¡å‹ï¼Œå¾ä¸åŒé ˜åŸŸäº¤å‰åˆ†æï¼Œå¹«ä½ çœ‹è¦‹è‡ªå·±çœ‹ä¸è¦‹çš„è§’åº¦ã€‚

## âš¡ å¿«é€Ÿå®‰è£

```bash
npx skills add kcchien/model-thinking
```

å°±é€™æ¨£ã€‚ç•¶ä½ è«‹ AI åŠ©æ‰‹å¹«ä½ åˆ†æå•é¡Œã€åšæ±ºç­–ã€æˆ–å­¸ç¿’æ€ç¶­æ¨¡å‹æ™‚ï¼Œå®ƒæœƒè‡ªå‹•å•Ÿç”¨ã€‚

## ğŸ’¬ ä½ å¯ä»¥æ€éº¼ç”¨ï¼Ÿ

ç”¨è‡ªç„¶èªè¨€è·Ÿä½ çš„ AI åŠ©æ‰‹å°è©±å³å¯ï¼š

| ä½ èªª | ç™¼ç”Ÿä»€éº¼äº‹ |
|------|-----------|
| *ã€ŒA å…¬å¸é–‹å¹´è–ª 200 è¬ä½†è¦ relocateï¼ŒB å…¬å¸ 150 è¬ä½†èƒ½é ç«¯ï¼Œæ€éº¼é¸ï¼Ÿã€* | ç”¨å¯é€†æ€§ã€æ©Ÿæœƒæˆæœ¬ã€10/10/10 æ³•å‰‡äº¤å‰åˆ†æå…©å€‹é¸é …çš„é•·æœŸå½±éŸ¿ |
| *ã€Œæˆ‘å€‘çš„å®¢æœå·¥å–®é‡æ¯å­£éƒ½ç¿»å€ï¼ŒåŠ äººå»æ²’æ”¹å–„ã€* | ç”¨ç³»çµ±åŸºæ¨¡ï¼ˆè½‰å«è² æ“” + æˆé•·æ¥µé™ï¼‰æ‰¾å‡ºåŠ äººåªæ˜¯ç—‡ç‹€è™•ç†çš„æ ¹å›  |
| *ã€Œè¶Šå—åŠå°é«”å» ç”¨æ°´å¸‚å ´ï¼Œæˆ‘å€‘è©²ç¬¬ä¸€å€‹é€²å»å—ï¼Ÿã€* | ç”¨å…ˆè¡Œè€…å„ªå‹¢ã€ç¶²è·¯æ•ˆæ‡‰ã€è‚¥å°¾é¢¨éšªä¸‰è§’é©—è­‰ï¼Œçµ¦å‡ºé€²å…¥ç­–ç•¥èˆ‡ä¸‹æ³¨è¦æ¨¡ |
| *ã€Œæ•™æˆ‘ä»€éº¼æ˜¯äºŒéšæ€è€ƒï¼Œç”¨ç”¢å“å®šåƒ¹ç•¶ä¾‹å­ã€* | æ•™å­¸æ¨¡å¼ï¼šæ¦‚å¿µå®šç¾© â†’ å®šåƒ¹çš„ä¸€éš/äºŒéš/ä¸‰éšæ•ˆæ‡‰ â†’ å¸¸è¦‹é™·é˜± â†’ ç·´ç¿’é¡Œ |
| *ã€Œç”¨ Pre-Mortem åˆ†ææˆ‘å€‘ Q3 çš„ç”¢å“ä¸Šç·šè¨ˆç•«ã€* | ç›´æ¥å¥—ç”¨äº‹å‰é©—å±æ³•ï¼Œåˆ—å‡ºã€Œå·²ç¶“å¤±æ•—äº†ï¼Œç‚ºä»€éº¼ï¼Ÿã€çš„é¢¨éšªæ¸…å–® |
| *ã€Œåœ˜éšŠè¦æ±ºå®šæŠ€è¡“æ£§ï¼Œäº”å€‹äººäº”ç¨®æ„è¦‹ï¼Œæ€éº¼æ”¶æ–‚ï¼Ÿã€* | å¼•å°æ¨¡å¼ï¼šå…ˆé‡æ¸…æ±ºç­–å¯é€†æ€§èˆ‡é—œéµæ¬Šé‡ï¼Œå†ç”¨åŠ æ¬Šæ±ºç­–çŸ©é™£ + å…­é ‚æ€è€ƒå¸½çµæ§‹åŒ–è¨è«– |

### ä¸‰ç¨®æ¨¡å¼ï¼Œè‡ªå‹•é©é…

| æ¨¡å¼ | è§¸ç™¼æ¢ä»¶ | ä½ æœƒå¾—åˆ°ä»€éº¼ |
|------|---------|------------|
| **å¼•å°æ¨¡å¼** | å•é¡Œæ¨¡ç³Šæˆ–è¤‡é›œ | 2-3 å€‹è¨ºæ–·å•é¡Œ â†’ æ¨¡å‹æ¨è–¦ â†’ çµæ§‹åŒ–åˆ†æ |
| **ç›´æ¥æ¨¡å¼** | å•é¡Œæ¸…æ¥šæˆ–æŒ‡å®šæ¨¡å‹ | ç«‹å³å¥—ç”¨ 2-3 å€‹æ¨¡å‹ï¼Œäº¤å‰é©—è­‰ |
| **æ•™å­¸æ¨¡å¼** | æƒ³å­¸ç¿’ç‰¹å®šæ¨¡å‹ | ä¸€å¥è©±å®šç¾© â†’ å…·é«”ç¯„ä¾‹ â†’ å¸¸è¦‹é™·é˜± â†’ ç·´ç¿’é¡Œ |

ä½ ä¸éœ€è¦çŸ¥é“å“ªå€‹æ¨¡å‹é©ç”¨â€”â€”æè¿°ä½ çš„å•é¡Œï¼ŒAI æœƒè‡ªå‹•é¸æ“‡ã€‚

## ğŸ§  åå¤§çŸ¥è­˜é ˜åŸŸ

ä¸åªæ˜¯æ¨¡å‹æ¸…å–®ï¼Œè€Œæ˜¯ä¸€å¥—æœ‰çµ„ç¹”çš„**æ€è€ƒå·¥å…·ç®±**ã€‚æ¯å€‹é ˜åŸŸç¨ç«‹æˆå†Šï¼ŒAI æŒ‰éœ€è¼‰å…¥ï¼Œä¸æµªè²»ä¸Šä¸‹æ–‡è¦–çª—ã€‚

| é ˜åŸŸ | æ¶µè“‹ä¸»é¡Œ | ä»£è¡¨æ¨¡å‹ |
|------|---------|---------|
| **æ±ºç­–** (Decisions) | é¸æ“‡ã€åˆ¤æ–·ã€èªçŸ¥å·¥å…· | åå‘æ€è€ƒã€äºŒéšæ•ˆæ‡‰ã€äº‹å‰é©—å±ã€å…­é ‚æ€è€ƒå¸½ |
| **ç³»çµ±** (Systems) | å›é¥‹è¿´è·¯ã€æ¹§ç¾ã€å¹²é  | å­˜é‡èˆ‡æµé‡ã€æ§“æ¡¿é»ã€æˆé•·æ¥µé™ã€è½‰å«è² æ“” |
| **çµ±è¨ˆ** (Statistics) | æ©Ÿç‡ã€æ¨è«–ã€è¬¬èª¤ | è²æ°æ€ç¶­ã€å›æ­¸å‡å€¼ã€å€–å­˜è€…åå·®ã€è¾›æ™®æ£®æ‚–è«– |
| **ç­–ç•¥** (Strategy) | è³½å±€ã€ç«¶çˆ­ã€è«‡åˆ¤ | ç´è¨±å‡è¡¡ã€å›šå¾’å›°å¢ƒã€BATNAã€è­·åŸæ²³ |
| **å¿ƒç†** (Psychology) | åèª¤ã€ç¤¾æœƒå¿ƒç†ã€å‹•æ©Ÿ | ç¢ºèªåèª¤ã€æå¤±è¶¨é¿ã€å¾çœ¾æ•ˆæ‡‰ã€é„§å¯§-å…‹é­¯æ ¼ |
| **ç¶²è·¯** (Networks) | é€£çµã€å½±éŸ¿åŠ›ã€å¹³å° | ç¶²è·¯æ•ˆæ‡‰ã€æ¢…ç‰¹å¡å¤«å®šå¾‹ã€å°ä¸–ç•Œã€å¼±é€£çµ |
| **æ¼”ç®—æ³•** (Algorithms) | è¨ˆç®—æ€ç¶­ã€æœå°‹ã€æ’åº | æ¢ç´¢/åˆ©ç”¨ã€æ¨¡æ“¬é€€ç«ã€è²ªå¿ƒæ³•ã€å¿«å–ç­–ç•¥ |
| **é¢¨éšª** (Risk) | ä¸ç¢ºå®šæ€§ã€è„†å¼±æ€§ã€é»‘å¤©éµ | è‚¥å°¾åˆ†ä½ˆã€åè„†å¼±ã€å®‰å…¨é‚Šéš›ã€æ§“éˆ´ç­–ç•¥ |
| **å­¸ç¿’** (Learning) | çŸ¥è­˜ç²å–ã€æŠ€èƒ½å»ºæ§‹ | é–“éš”é‡è¤‡ã€åˆ»æ„ç·´ç¿’ã€è²»æ›¼æŠ€å·§ã€èƒ½åŠ›åœˆ |
| **ç¶“æ¿Ÿ** (Economics) | å¸‚å ´ã€æ¿€å‹µã€è³‡æºé…ç½® | æ©Ÿæœƒæˆæœ¬ã€ä¾›éœ€ã€æ¯”è¼ƒå„ªå‹¢ã€å…¬åœ°æ‚²åŠ‡ |

### è·¨é ˜åŸŸçµ„åˆ â€” çœŸæ­£çš„å¨åŠ›æ‰€åœ¨

å–®ä¸€æ¨¡å‹åªçœ‹åˆ°ä¸€å€‹é¢å‘ã€‚**Model Thinking** çš„æ ¸å¿ƒåƒ¹å€¼æ˜¯è·¨é ˜åŸŸçµ„åˆï¼š

<img src="assets/flow1.jpeg" alt="è·¨é ˜åŸŸçµ„åˆç¯„ä¾‹ï¼šè©²ä¸è©²æ¨å‡ºæ–°ç”¢å“ï¼Ÿ" width="100%"/>

æ¨¡å‹ä¹‹é–“**åŒæ„** = é«˜ä¿¡å¿ƒã€‚æ¨¡å‹ä¹‹é–“**ä¸åŒæ„** = å€¼å¾—æ·±æŒ–çš„è¤‡é›œæ€§ã€‚

## âš™ï¸ é‹ä½œåŸç†

**æ¼¸é€²å¼æ­éœ²æ¶æ§‹** â€” AI ä¸æœƒä¸€æ¬¡è¼‰å…¥æ‰€æœ‰æ¨¡å‹ï¼Œè€Œæ˜¯æŒ‰éœ€å–ç”¨ï¼š

| éšæ®µ | è¼‰å…¥ä»€éº¼ | ä¸Šä¸‹æ–‡æˆæœ¬ |
|------|---------|-----------|
| å¾…æ©Ÿ | æŠ€èƒ½åç¨± + è§¸ç™¼æè¿° | ~100 è© |
| å•Ÿå‹• | SKILL.md æ ¸å¿ƒå·¥ä½œæµ | ~800 è© |
| åˆ†æ | ç›¸é—œé ˜åŸŸçš„åƒè€ƒæª”ï¼ˆ1-2 å€‹ï¼‰ | ~3,000 è©/æª” |
| çµ„åˆ | combinations.mdï¼ˆæŒ‰éœ€ï¼‰ | ~2,000 è© |

é€™ä»£è¡¨ä½ çš„ä¸Šä¸‹æ–‡è¦–çª—ä¸æœƒè¢«ç”¨ä¸åˆ°çš„æ¨¡å‹å¡æ»¿ã€‚AI åªè®€å®ƒéœ€è¦çš„æ±è¥¿ã€‚

### åˆ†ææµç¨‹

<img src="assets/flow2.png" alt="åˆ†ææµç¨‹" width="100%"/>

## ğŸ“ æŠ€èƒ½çµæ§‹

```
model-thinking/
â”œâ”€â”€ SKILL.md                        # AI æŒ‡ä»¤å…¥å£ï¼ˆå·¥ä½œæµ + æ¨¡æ¿ + è·¯ç”±è¡¨ï¼‰
â””â”€â”€ references/
    â”œâ”€â”€ decisions.md                # æ±ºç­–æ¨¡å‹ï¼ˆ25 å€‹ï¼‰
    â”œâ”€â”€ systems.md                  # ç³»çµ±æ¨¡å‹ï¼ˆ24 å€‹ï¼‰
    â”œâ”€â”€ statistics.md               # çµ±è¨ˆæ¨¡å‹
    â”œâ”€â”€ strategy.md                 # ç­–ç•¥æ¨¡å‹
    â”œâ”€â”€ psychology.md               # å¿ƒç†æ¨¡å‹ï¼ˆ27 å€‹ï¼‰
    â”œâ”€â”€ networks.md                 # ç¶²è·¯æ¨¡å‹
    â”œâ”€â”€ algorithms.md               # æ¼”ç®—æ³•æ¨¡å‹
    â”œâ”€â”€ risk.md                     # é¢¨éšªæ¨¡å‹
    â”œâ”€â”€ learning.md                 # å­¸ç¿’æ¨¡å‹
    â”œâ”€â”€ economics.md                # ç¶“æ¿Ÿæ¨¡å‹
    â””â”€â”€ combinations.md             # è·¨é ˜åŸŸçµ„åˆç­–ç•¥ï¼ˆ5 å€‹æƒ…å¢ƒç¯„ä¾‹ï¼‰
```

## ğŸ¤ ç›¸å®¹çš„ AI Agent

| Agent | å®‰è£æ–¹å¼ |
|-------|---------|
| [Claude Code](https://docs.anthropic.com/en/docs/claude-code) | `npx skills add kcchien/model-thinking` |
| å…¶ä»–ç›¸å®¹ Agent | ä»»ä½•èƒ½è®€å– `SKILL.md` ä½œç‚ºæŒ‡ä»¤çš„ AI Agent |

> Model Thinking éµå¾ªé–‹æ”¾çš„ `SKILL.md` æ…£ä¾‹ã€‚ä»»ä½•èƒ½ç™¼ç¾ä¸¦è¼‰å…¥ `SKILL.md` çš„ AI Agent éƒ½èƒ½ä½¿ç”¨ã€‚

## ğŸ“‹ å‰ç½®æ¢ä»¶

- æ”¯æ´ Agent Skills çš„ AI ç·¨ç¢¼åŠ©æ‰‹ï¼ˆä¾‹å¦‚ [Claude Code](https://docs.anthropic.com/en/docs/claude-code)ï¼‰
- **é›¶é¡å¤–ä¾è³´** â€” ä¸éœ€è¦ Pythonã€ä¸éœ€è¦ API keyã€ä¸éœ€è¦å®‰è£ä»»ä½•å¥—ä»¶

## ğŸ“– é™„éŒ„ï¼šå®Œæ•´æ¨¡å‹æ¸…å–®ï¼ˆ253 å€‹ï¼‰

<details>
<summary><strong>æ±ºç­– (Decisions) â€” 25 å€‹</strong></summary>

Inversion Â· Second-Order Thinking Â· Probabilistic Thinking Â· Expected Value Â· Regret Minimization Â· Pre-Mortem Â· Two-Way vs One-Way Door Â· Circle of Competence Â· Occam's Razor Â· Hanlon's Razor Â· First Principles Thinking Â· Falsifiability Â· Devil's Advocate Â· Six Thinking Hats Â· Opportunity Cost Â· Marginal Thinking Â· Sunk Cost Fallacy Â· Asymmetric Risk-Reward Â· Satisficing vs Maximizing Â· Temporal Discounting Â· Commitment Devices Â· Option Value Â· Weighted Decision Matrix Â· 10/10/10 Rule Â· WRAP Framework

</details>

<details>
<summary><strong>ç³»çµ± (Systems) â€” 24 å€‹</strong></summary>

Stocks and Flows Â· System Boundaries Â· Hierarchy and Subsystems Â· Resilience Â· Reinforcing Feedback Loops Â· Balancing Feedback Loops Â· Delays Â· Dominance Shifting Â· Oscillation Â· Exponential Growth Â· Emergence Â· Non-linearity Â· Chaos and Sensitivity Â· Attractors Â· Path Dependence Â· Self-Organization Â· Adaptive Systems Â· Leverage Points Â· Unintended Consequences Â· Policy Resistance Â· Shifting the Burden Â· Fixes That Fail Â· Limits to Growth Â· Tragedy of the Commons

</details>

<details>
<summary><strong>çµ±è¨ˆ (Statistics) â€” 25 å€‹</strong></summary>

Bayes' Theorem Â· Base Rates Â· Conditional Probability Â· Independence Â· Law of Large Numbers Â· Expected Value Â· Normal Distribution Â· Power Laws Â· Fat Tails Â· Regression to the Mean Â· Simpson's Paradox Â· Survivorship Bias Â· Signal vs Noise Â· Confidence Intervals Â· Correlation vs Causation Â· Selection Bias Â· Overfitting Â· Sample Size Effects Â· Multiple Comparisons Problem Â· Gambler's Fallacy Â· Hot Hand Fallacy Â· Neglect of Probability Â· Conjunction Fallacy Â· Denominator Neglect Â· Availability Heuristic

</details>

<details>
<summary><strong>ç­–ç•¥ (Strategy) â€” 26 å€‹</strong></summary>

Nash Equilibrium Â· Prisoner's Dilemma Â· Zero-Sum vs Positive-Sum Â· Repeated Games Â· Tit-for-Tat Â· Chicken Game Â· Stag Hunt Â· Moats Â· Porter's Five Forces Â· Relative vs Absolute Advantage Â· First-Mover vs Fast-Follower Â· Blue Ocean Strategy Â· Disruptive Innovation Â· Red Queen Effect Â· BATNA Â· ZOPA Â· Integrative vs Distributive Bargaining Â· Anchoring in Negotiation Â· Commitment and Consistency Â· Reciprocity Â· Schelling Points Â· Commitment Devices Â· Signaling Â· Information Asymmetry Â· Option Value in Strategy Â· Precommitment

</details>

<details>
<summary><strong>å¿ƒç† (Psychology) â€” 27 å€‹</strong></summary>

Confirmation Bias Â· Availability Heuristic Â· Anchoring Â· Hindsight Bias Â· Overconfidence Â· Dunning-Kruger Effect Â· Status Quo Bias Â· Framing Effects Â· Loss Aversion Â· Peak-End Rule Â· Recency and Primacy Effects Â· Halo Effect Â· Fundamental Attribution Error Â· Representativeness Heuristic Â· Social Proof Â· Authority Bias Â· Liking Bias Â· Commitment and Consistency Â· In-Group/Out-Group Bias Â· Groupthink Â· Bystander Effect Â· Incentive-Caused Bias Â· Reactance Â· Hedonic Treadmill Â· Maslow's Hierarchy Â· Self-Serving Bias Â· Sunk Cost Fallacy

</details>

<details>
<summary><strong>ç¶²è·¯ (Networks) â€” 25 å€‹</strong></summary>

Nodes and Edges Â· Network Density Â· Degree Distribution Â· Hub Nodes Â· Network Clustering Â· Bridges and Structural Holes Â· Strong vs Weak Ties Â· Small World Networks Â· Preferential Attachment Â· Network Effects Â· Critical Mass Â· Tipping Points Â· Cascade Failures Â· Social Contagion Â· Information Cascade Â· Viral Spread Â· Seeding Strategies Â· Echo Chambers Â· Dunbar's Number Â· Two-Sided Markets Â· Multi-Sided Platforms Â· Switching Costs and Lock-In Â· Disintermediation Â· Network Orchestration Â· Ecosystem Strategy

</details>

<details>
<summary><strong>æ¼”ç®—æ³• (Algorithms) â€” 25 å€‹</strong></summary>

Optimal Stopping (37% Rule) Â· Look-Then-Leap Rule Â· Secretary Problem Variants Â· Multi-Armed Bandit Â· Explore/Exploit Trade-off Â· Gittins Index Â· Comparison Sorts Â· Bucket Sort Â· Search Costs Â· LRU Cache Â· Noguchi Filing System Â· Earliest Due Date Â· Shortest Job First Â· Weighted Shortest Job First Â· Priority Inversion Â· Interrupt Coalescing Â· Context Switching Costs Â· Thrashing Â· Gradient Descent Â· Simulated Annealing Â· Hill Climbing Â· Randomness in Optimization Â· Relaxation Â· Constraint Satisfaction Â· Lagrangian Relaxation

</details>

<details>
<summary><strong>é¢¨éšª (Risk) â€” 25 å€‹</strong></summary>

Risk vs Uncertainty Â· Aleatory vs Epistemic Uncertainty Â· Known Knowns Matrix Â· Calibrated Uncertainty Â· Ergodicity Â· Fragile Â· Robust Â· Antifragile Â· Hormesis Â· Via Negativa Â· Black Swans Â· Fat Tails vs Thin Tails Â· Ludic Fallacy Â· Turkey Problem Â· Extremistan vs Mediocristan Â· Precautionary Principle Â· Margin of Safety Â· Barbell Strategy Â· Redundancy Â· Position Sizing Â· Asymmetric Payoffs Â· Skin in the Game Â· Small Bets Â· Reversibility Premium Â· Correlation in Crisis

</details>

<details>
<summary><strong>å­¸ç¿’ (Learning) â€” 25 å€‹</strong></summary>

Circle of Competence Â· T-Shaped Knowledge Â· Spacing Effect Â· Testing Effect Â· Interleaving Â· Elaboration Â· Dual Coding Â· Deliberate Practice Â· 10,000 Hour Rule Â· Competence Ladder Â· Plateau Effect Â· Transfer of Learning Â· Zeigarnik Effect Â· Growth vs Fixed Mindset Â· Desirable Difficulties Â· Fail Fast, Learn Fast Â· Antifragility in Learning Â· Explore/Exploit Trade-off Â· Compounding Knowledge Â· Feynman Technique Â· Analogical Reasoning Â· Scaffolding Â· Cognitive Load Theory Â· Zone of Proximal Development Â· Chunking

</details>

<details>
<summary><strong>ç¶“æ¿Ÿ (Economics) â€” 26 å€‹</strong></summary>

Supply and Demand Â· Opportunity Cost Â· Marginal Thinking Â· Comparative Advantage Â· Diminishing Returns Â· Economies of Scale Â· Invisible Hand Â· Creative Destruction Â· Externalities Â· Market Failure Â· Price Elasticity Â· Arbitrage Â· Bubbles and Crashes Â· Incentives Â· Principal-Agent Problem Â· Moral Hazard Â· Adverse Selection Â· Tragedy of the Commons Â· Free Rider Problem Â· Subjective Value Â· Price Discrimination Â· Bundling Â· Network Effects Â· Two-Sided Markets Â· Switching Costs Â· Auctions and Price Discovery

</details>

## ğŸ“„ æˆæ¬Š

[MIT](LICENSE)

---

<div align="center">

<img src="assets/cover.png" alt="Model Thinking â€” Mental Models Toolkit" width="100%"/>

# Model Thinking

**200+ mental models in your AI assistant. Think wider, decide better.**

<br/>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](LICENSE)
[![Agent Skill](https://img.shields.io/badge/Agent_Skill-Compatible-blueviolet?style=flat-square)](#-compatible-agents)
[![Domains](https://img.shields.io/badge/Domains-10-34d399?style=flat-square)](#-ten-knowledge-domains)
[![Models](https://img.shields.io/badge/Models-253-60a5fa?style=flat-square)](#-ten-knowledge-domains)
[![Zero Dependencies](https://img.shields.io/badge/Zero_Deps-Install_and_Go-f59e0b?style=flat-square)](#-requirements)

An AI-native thinking toolkit that equips your assistant with 200+ mental models<br/>
across 10 domains â€” with cross-domain synthesis for real-world problems.

[Quick Install](#-quick-install-1) Â· [Usage](#-what-can-you-do-with-it) Â· [Domains](#-ten-knowledge-domains) Â· [How It Works](#ï¸-how-it-works-1)

</div>

---

When you face a complex decision, how many angles do you consider?

Most people rely on one or two familiar perspectives. The result: blind spots, circular thinking, or analysis paralysis.

**Model Thinking** turns your AI assistant into a thinking partner armed with 200+ mental models. It doesn't hand you a reading list â€” it selects 2-3 models that fit your specific problem, cross-references them across domains, and surfaces the angles you'd miss on your own.

## âš¡ Quick Install

```bash
npx skills add kcchien/model-thinking
```

That's it. Your AI agent will automatically activate when you ask it to analyze problems, make decisions, or learn about mental models.

## ğŸ’¬ What Can You Do With It?

Just talk to your AI assistant naturally:

| You say | What happens |
|---------|-------------|
| *"Company A offers $150K but requires relocation; B offers $120K remote. How to decide?"* | Cross-analyzes with Reversibility, Opportunity Cost, and 10/10/10 Rule for long-term impact |
| *"Our support tickets double every quarter â€” hiring more agents isn't helping"* | Diagnoses with system archetypes (Shifting the Burden + Limits to Growth) to find the real bottleneck |
| *"Vietnam semiconductor fab water market â€” should we be first in?"* | Triangulates First Mover Advantage, Network Effects, and Fat Tail Risk; recommends entry strategy and bet size |
| *"Teach me second-order thinking using product pricing as the example"* | Teaching mode: definition â†’ first/second/third-order effects of pricing â†’ common pitfalls â†’ practice prompt |
| *"Run a Pre-Mortem on our Q3 product launch plan"* | Directly applies Pre-Mortem: "It's 6 months later and we failed â€” why?" risk inventory |
| *"Team needs to pick a tech stack â€” 5 people, 5 opinions. How to converge?"* | Guided mode: clarifies reversibility and key criteria, then applies Weighted Decision Matrix + Six Thinking Hats |

### Three Modes, Auto-Selected

| Mode | Trigger | What You Get |
|------|---------|-------------|
| **Guided** | Ambiguous or complex problem | 2-3 diagnostic questions â†’ model recommendations â†’ structured analysis |
| **Direct** | Clear problem or specific model requested | Immediate 2-3 model application with cross-validation |
| **Teaching** | Wants to learn a model | One-liner â†’ concrete example â†’ common pitfall â†’ practice prompt |

You don't need to know which model to use â€” describe your problem, and the AI selects automatically.

## ğŸ§  Ten Knowledge Domains

Not just a model catalog, but an organized **thinking toolkit**. Each domain is a separate reference file, loaded on demand to preserve your context window.

| Domain | Topics | Representative Models |
|--------|--------|----------------------|
| **Decisions** | Choice, judgment, cognitive tools | Inversion, Second-Order Thinking, Pre-Mortem, Six Thinking Hats |
| **Systems** | Feedback loops, emergence, intervention | Stocks & Flows, Leverage Points, Limits to Growth, Shifting the Burden |
| **Statistics** | Probability, inference, fallacies | Bayesian Thinking, Regression to Mean, Survivorship Bias, Simpson's Paradox |
| **Strategy** | Game theory, competition, negotiation | Nash Equilibrium, Prisoner's Dilemma, BATNA, Moats |
| **Psychology** | Biases, social psychology, motivation | Confirmation Bias, Loss Aversion, Social Proof, Dunning-Kruger |
| **Networks** | Connections, influence, platforms | Network Effects, Metcalfe's Law, Small Worlds, Weak Ties |
| **Algorithms** | Computational thinking, search, sorting | Explore/Exploit, Simulated Annealing, Greedy, Caching |
| **Risk** | Uncertainty, fragility, black swans | Fat Tails, Antifragile, Margin of Safety, Barbell Strategy |
| **Learning** | Knowledge acquisition, skill building | Spaced Repetition, Deliberate Practice, Feynman Technique, Circle of Competence |
| **Economics** | Markets, incentives, resource allocation | Opportunity Cost, Supply & Demand, Comparative Advantage, Tragedy of the Commons |

### Cross-Domain Synthesis â€” Where the Real Power Lives

A single model reveals one dimension. **Model Thinking**'s core value is cross-domain combination:

- **Models agree** â†’ High confidence in the conclusion
- **Models disagree** â†’ Hidden complexity worth exploring before deciding
- Each model's blind spot is covered by another's strength

The skill includes a dedicated `combinations.md` reference with battle-tested pairing strategies and five detailed scenario walkthroughs.

## âš™ï¸ How It Works

**Progressive disclosure architecture** â€” the AI doesn't load all models at once, but pulls them on demand:

| Stage | What Loads | Context Cost |
|-------|-----------|-------------|
| Standby | Skill name + trigger description | ~100 words |
| Activation | SKILL.md core workflow | ~800 words |
| Analysis | Relevant domain reference files (1-2) | ~3,000 words/file |
| Synthesis | combinations.md (on demand) | ~2,000 words |

Your context window stays clean. The AI only reads what it needs.

## ğŸ“ Skill Structure

```
model-thinking/
â”œâ”€â”€ SKILL.md                        # Agent instructions (workflow + templates + routing)
â””â”€â”€ references/
    â”œâ”€â”€ decisions.md                # Decision models (25)
    â”œâ”€â”€ systems.md                  # Systems models (24)
    â”œâ”€â”€ statistics.md               # Statistics models
    â”œâ”€â”€ strategy.md                 # Strategy models
    â”œâ”€â”€ psychology.md               # Psychology models (27)
    â”œâ”€â”€ networks.md                 # Network models
    â”œâ”€â”€ algorithms.md               # Algorithm models
    â”œâ”€â”€ risk.md                     # Risk models
    â”œâ”€â”€ learning.md                 # Learning models
    â”œâ”€â”€ economics.md                # Economics models
    â””â”€â”€ combinations.md             # Cross-domain combination strategies (5 scenarios)
```

## ğŸ¤ Compatible Agents

| Agent | Install Method |
|-------|---------------|
| [Claude Code](https://docs.anthropic.com/en/docs/claude-code) | `npx skills add kcchien/model-thinking` |
| Other compatible agents | Any agent that reads `SKILL.md` as instructions |

> Model Thinking follows the open `SKILL.md` convention. Any AI agent that can discover and load `SKILL.md` files will work.

## ğŸ“‹ Requirements

- An AI coding assistant that supports Agent Skills (e.g., [Claude Code](https://docs.anthropic.com/en/docs/claude-code))
- **Zero additional dependencies** â€” no Python, no API keys, no packages to install

## ğŸ“– Appendix: Complete Model List (253)

<details>
<summary><strong>Decisions â€” 25</strong></summary>

Inversion Â· Second-Order Thinking Â· Probabilistic Thinking Â· Expected Value Â· Regret Minimization Â· Pre-Mortem Â· Two-Way vs One-Way Door Â· Circle of Competence Â· Occam's Razor Â· Hanlon's Razor Â· First Principles Thinking Â· Falsifiability Â· Devil's Advocate Â· Six Thinking Hats Â· Opportunity Cost Â· Marginal Thinking Â· Sunk Cost Fallacy Â· Asymmetric Risk-Reward Â· Satisficing vs Maximizing Â· Temporal Discounting Â· Commitment Devices Â· Option Value Â· Weighted Decision Matrix Â· 10/10/10 Rule Â· WRAP Framework

</details>

<details>
<summary><strong>Systems â€” 24</strong></summary>

Stocks and Flows Â· System Boundaries Â· Hierarchy and Subsystems Â· Resilience Â· Reinforcing Feedback Loops Â· Balancing Feedback Loops Â· Delays Â· Dominance Shifting Â· Oscillation Â· Exponential Growth Â· Emergence Â· Non-linearity Â· Chaos and Sensitivity Â· Attractors Â· Path Dependence Â· Self-Organization Â· Adaptive Systems Â· Leverage Points Â· Unintended Consequences Â· Policy Resistance Â· Shifting the Burden Â· Fixes That Fail Â· Limits to Growth Â· Tragedy of the Commons

</details>

<details>
<summary><strong>Statistics â€” 25</strong></summary>

Bayes' Theorem Â· Base Rates Â· Conditional Probability Â· Independence Â· Law of Large Numbers Â· Expected Value Â· Normal Distribution Â· Power Laws Â· Fat Tails Â· Regression to the Mean Â· Simpson's Paradox Â· Survivorship Bias Â· Signal vs Noise Â· Confidence Intervals Â· Correlation vs Causation Â· Selection Bias Â· Overfitting Â· Sample Size Effects Â· Multiple Comparisons Problem Â· Gambler's Fallacy Â· Hot Hand Fallacy Â· Neglect of Probability Â· Conjunction Fallacy Â· Denominator Neglect Â· Availability Heuristic

</details>

<details>
<summary><strong>Strategy â€” 26</strong></summary>

Nash Equilibrium Â· Prisoner's Dilemma Â· Zero-Sum vs Positive-Sum Â· Repeated Games Â· Tit-for-Tat Â· Chicken Game Â· Stag Hunt Â· Moats Â· Porter's Five Forces Â· Relative vs Absolute Advantage Â· First-Mover vs Fast-Follower Â· Blue Ocean Strategy Â· Disruptive Innovation Â· Red Queen Effect Â· BATNA Â· ZOPA Â· Integrative vs Distributive Bargaining Â· Anchoring in Negotiation Â· Commitment and Consistency Â· Reciprocity Â· Schelling Points Â· Commitment Devices Â· Signaling Â· Information Asymmetry Â· Option Value in Strategy Â· Precommitment

</details>

<details>
<summary><strong>Psychology â€” 27</strong></summary>

Confirmation Bias Â· Availability Heuristic Â· Anchoring Â· Hindsight Bias Â· Overconfidence Â· Dunning-Kruger Effect Â· Status Quo Bias Â· Framing Effects Â· Loss Aversion Â· Peak-End Rule Â· Recency and Primacy Effects Â· Halo Effect Â· Fundamental Attribution Error Â· Representativeness Heuristic Â· Social Proof Â· Authority Bias Â· Liking Bias Â· Commitment and Consistency Â· In-Group/Out-Group Bias Â· Groupthink Â· Bystander Effect Â· Incentive-Caused Bias Â· Reactance Â· Hedonic Treadmill Â· Maslow's Hierarchy Â· Self-Serving Bias Â· Sunk Cost Fallacy

</details>

<details>
<summary><strong>Networks â€” 25</strong></summary>

Nodes and Edges Â· Network Density Â· Degree Distribution Â· Hub Nodes Â· Network Clustering Â· Bridges and Structural Holes Â· Strong vs Weak Ties Â· Small World Networks Â· Preferential Attachment Â· Network Effects Â· Critical Mass Â· Tipping Points Â· Cascade Failures Â· Social Contagion Â· Information Cascade Â· Viral Spread Â· Seeding Strategies Â· Echo Chambers Â· Dunbar's Number Â· Two-Sided Markets Â· Multi-Sided Platforms Â· Switching Costs and Lock-In Â· Disintermediation Â· Network Orchestration Â· Ecosystem Strategy

</details>

<details>
<summary><strong>Algorithms â€” 25</strong></summary>

Optimal Stopping (37% Rule) Â· Look-Then-Leap Rule Â· Secretary Problem Variants Â· Multi-Armed Bandit Â· Explore/Exploit Trade-off Â· Gittins Index Â· Comparison Sorts Â· Bucket Sort Â· Search Costs Â· LRU Cache Â· Noguchi Filing System Â· Earliest Due Date Â· Shortest Job First Â· Weighted Shortest Job First Â· Priority Inversion Â· Interrupt Coalescing Â· Context Switching Costs Â· Thrashing Â· Gradient Descent Â· Simulated Annealing Â· Hill Climbing Â· Randomness in Optimization Â· Relaxation Â· Constraint Satisfaction Â· Lagrangian Relaxation

</details>

<details>
<summary><strong>Risk â€” 25</strong></summary>

Risk vs Uncertainty Â· Aleatory vs Epistemic Uncertainty Â· Known Knowns Matrix Â· Calibrated Uncertainty Â· Ergodicity Â· Fragile Â· Robust Â· Antifragile Â· Hormesis Â· Via Negativa Â· Black Swans Â· Fat Tails vs Thin Tails Â· Ludic Fallacy Â· Turkey Problem Â· Extremistan vs Mediocristan Â· Precautionary Principle Â· Margin of Safety Â· Barbell Strategy Â· Redundancy Â· Position Sizing Â· Asymmetric Payoffs Â· Skin in the Game Â· Small Bets Â· Reversibility Premium Â· Correlation in Crisis

</details>

<details>
<summary><strong>Learning â€” 25</strong></summary>

Circle of Competence Â· T-Shaped Knowledge Â· Spacing Effect Â· Testing Effect Â· Interleaving Â· Elaboration Â· Dual Coding Â· Deliberate Practice Â· 10,000 Hour Rule Â· Competence Ladder Â· Plateau Effect Â· Transfer of Learning Â· Zeigarnik Effect Â· Growth vs Fixed Mindset Â· Desirable Difficulties Â· Fail Fast, Learn Fast Â· Antifragility in Learning Â· Explore/Exploit Trade-off Â· Compounding Knowledge Â· Feynman Technique Â· Analogical Reasoning Â· Scaffolding Â· Cognitive Load Theory Â· Zone of Proximal Development Â· Chunking

</details>

<details>
<summary><strong>Economics â€” 26</strong></summary>

Supply and Demand Â· Opportunity Cost Â· Marginal Thinking Â· Comparative Advantage Â· Diminishing Returns Â· Economies of Scale Â· Invisible Hand Â· Creative Destruction Â· Externalities Â· Market Failure Â· Price Elasticity Â· Arbitrage Â· Bubbles and Crashes Â· Incentives Â· Principal-Agent Problem Â· Moral Hazard Â· Adverse Selection Â· Tragedy of the Commons Â· Free Rider Problem Â· Subjective Value Â· Price Discrimination Â· Bundling Â· Network Effects Â· Two-Sided Markets Â· Switching Costs Â· Auctions and Price Discovery

</details>

## ğŸ“„ License

[MIT](LICENSE)
